{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "049c267d-1e67-bb8d-27bc-bcee1e74cd31"
   },
   "source": [
    "# STUDENT PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5ff9d9c7-5a83-b85e-6c2b-2c408f749c3a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9801518d6988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmtplib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ticks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdBu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#sns.set(style='ticks', palette='Set2')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='RdBu')\n",
    "#sns.set(style='ticks', palette='Set2')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "pd.options.display.max_colwidth = 1000\n",
    "from time import gmtime, strftime\n",
    "Time_now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import svm\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b70e4561-e2a2-f467-3c0d-4f6fdfab8784"
   },
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39a13fc9-aa7f-9a3e-d795-bfab1e0eb3ae"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset/xAPI-Edu-Data.csv')\n",
    "df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2871a4de-1e81-bdcd-f16d-d10255790ac1"
   },
   "source": [
    "# Describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe414fa2-989b-5c69-295d-d3f4128e93a6"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a7e9e16-111d-d51a-d172-3c6dabaf40f4"
   },
   "outputs": [],
   "source": [
    "data.head(n=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "06945578-3213-5482-cf97-1f55b975200a"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "727d2936-5af3-1af0-86b2-00f1f8d50a27"
   },
   "source": [
    "# Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7361802e-dd06-528e-b4d7-bd3eda7bdaef"
   },
   "outputs": [],
   "source": [
    "categorical_features = (data.select_dtypes(include=['object']).columns.values)\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2300b504-1175-5a2a-7731-040755dda959"
   },
   "source": [
    "# Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5697d86c-1250-4efb-98c4-b376e1cdb6d7"
   },
   "outputs": [],
   "source": [
    "numerical_features = data.select_dtypes(include = ['float64', 'int64']).columns.values\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd410f59-fe16-6dbb-1109-b37dde98dfd3"
   },
   "source": [
    "# Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "691384c0-23af-0716-c6de-4aab9f3b9106"
   },
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(df,\n",
    "            values = ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion'],\n",
    "            index = ['gender', 'NationalITy', 'PlaceofBirth'], \n",
    "                       columns= ['ParentschoolSatisfaction'],\n",
    "                       aggfunc=[np.mean], \n",
    "                       margins=True).fillna('')\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3febf0f6-e5d4-40d8-fc33-f7134b50c182"
   },
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(df,\n",
    "            values = ['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion'],\n",
    "            index = ['gender', 'NationalITy', 'PlaceofBirth'], \n",
    "                       columns= ['ParentschoolSatisfaction'],\n",
    "                       aggfunc=[np.mean, np.std], \n",
    "                       margins=True)\n",
    "cmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\n",
    "plt.subplots(figsize = (30, 20))\n",
    "sns.heatmap(pivot,linewidths=0.2,square=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "26fa347c-b78d-515d-98bd-01048cd5e87f"
   },
   "source": [
    "# Simple plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "687e5993-dc51-c6a3-2b88-a5ea3fcf5d42"
   },
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c2b6dac-6078-531d-dedb-f9dc83c182b8"
   },
   "outputs": [],
   "source": [
    "def heat_map(corrs_mat):\n",
    "    sns.set(style=\"white\")\n",
    "    f, ax = plt.subplots(figsize=(20, 20))\n",
    "    mask = np.zeros_like(corrs_mat, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True \n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(corrs_mat, mask=mask, cmap=cmap, ax=ax)\n",
    "\n",
    "variable_correlations = df.corr()\n",
    "#variable_correlations\n",
    "heat_map(variable_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aa336211-b734-2a0c-3a23-7c361497cfdc"
   },
   "outputs": [],
   "source": [
    "df_small = df[['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion', 'NationalITy']]\n",
    "sns.pairplot(df_small, hue='NationalITy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7f3454f-f8e6-cb16-b7d5-9fd1982d8223"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7efb1062-c68f-33b9-a510-cad45b032b30"
   },
   "source": [
    "# Complex plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abb3a1b7-5784-df4b-1140-3f7726373494"
   },
   "source": [
    "# Modify the original dataframe itself to make variables as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca2b61c2-0fde-65c6-8fc2-0a05d03dc622"
   },
   "outputs": [],
   "source": [
    "mod_df = df \n",
    "\n",
    "gender_map = {'M':1, \n",
    "              'F':2}\n",
    "\n",
    "NationalITy_map = {  'Iran': 1,\n",
    "                     'SaudiArabia': 2,\n",
    "                     'USA': 3,\n",
    "                     'Egypt': 4,\n",
    "                     'Lybia': 5,\n",
    "                     'lebanon': 6,\n",
    "                     'Morocco': 7,\n",
    "                     'Jordan': 8,\n",
    "                     'Palestine': 9,\n",
    "                     'Syria': 10,\n",
    "                     'Tunis': 11,\n",
    "                     'KW': 12,\n",
    "                     'KuwaIT': 12,\n",
    "                     'Iraq': 13,\n",
    "                     'venzuela': 14}\n",
    "PlaceofBirth_map =  {'Iran': 1,\n",
    "                     'SaudiArabia': 2,\n",
    "                     'USA': 3,\n",
    "                     'Egypt': 4,\n",
    "                     'Lybia': 5,\n",
    "                     'lebanon': 6,\n",
    "                     'Morocco': 7,\n",
    "                     'Jordan': 8,\n",
    "                     'Palestine': 9,\n",
    "                     'Syria': 10,\n",
    "                     'Tunis': 11,\n",
    "                     'KW': 12,\n",
    "                     'KuwaIT': 12,\n",
    "                     'Iraq': 13,\n",
    "                     'venzuela': 14}\n",
    "\n",
    "StageID_map = {'HighSchool':1, \n",
    "               'lowerlevel':2, \n",
    "               'MiddleSchool':3}\n",
    "\n",
    "GradeID_map =   {'G-02':2,\n",
    "                 'G-08':8,\n",
    "                 'G-09':9,\n",
    "                 'G-04':4,\n",
    "                 'G-05':5,\n",
    "                 'G-06':6,\n",
    "                 'G-07':7,\n",
    "                 'G-12':12,\n",
    "                 'G-11':11,\n",
    "                 'G-10':10}\n",
    "\n",
    "SectionID_map = {'A':1, \n",
    "                 'C':2, \n",
    "                 'B':3}\n",
    "\n",
    "Topic_map  =    {'Biology' : 1,\n",
    "                 'Geology' : 2,\n",
    "                 'Quran' : 3,\n",
    "                 'Science' : 4,\n",
    "                 'Spanish' : 5,\n",
    "                 'IT' : 6,\n",
    "                 'French' : 7,\n",
    "                 'English' :8,\n",
    "                 'Arabic' :9,\n",
    "                 'Chemistry' :10,\n",
    "                 'Math' :11,\n",
    "                 'History' : 12}\n",
    "Semester_map = {'S':1, \n",
    "                'F':2}\n",
    "\n",
    "Relation_map = {'Mum':2, \n",
    "                'Father':1} \n",
    "\n",
    "ParentAnsweringSurvey_map = {'Yes':1,\n",
    "                             'No':0}\n",
    "\n",
    "ParentschoolSatisfaction_map = {'Bad':0,\n",
    "                                'Good':1}\n",
    "\n",
    "StudentAbsenceDays_map = {'Under-7':0,\n",
    "                          'Above-7':1}\n",
    "\n",
    "Class_map = {'H':10,\n",
    "             'M':5,\n",
    "             'L':2}\n",
    "\n",
    "mod_df.gender  = mod_df.gender.map(gender_map)\n",
    "mod_df.NationalITy     = mod_df.NationalITy.map(NationalITy_map)\n",
    "mod_df.PlaceofBirth     = mod_df.PlaceofBirth.map(PlaceofBirth_map)\n",
    "mod_df.StageID       = mod_df.StageID.map(StageID_map)\n",
    "mod_df.GradeID = mod_df.GradeID.map(GradeID_map)\n",
    "mod_df.SectionID    = mod_df.SectionID.map(SectionID_map)\n",
    "mod_df.Topic     = mod_df.Topic.map(Topic_map)\n",
    "mod_df.Semester   = mod_df.Semester.map(Semester_map)\n",
    "mod_df.Relation   = mod_df.Relation.map(Relation_map)\n",
    "mod_df.ParentAnsweringSurvey   = mod_df.ParentAnsweringSurvey.map(ParentAnsweringSurvey_map)\n",
    "mod_df.ParentschoolSatisfaction   = mod_df.ParentschoolSatisfaction.map(ParentschoolSatisfaction_map)\n",
    "mod_df.StudentAbsenceDays   = mod_df.StudentAbsenceDays.map(StudentAbsenceDays_map)\n",
    "mod_df.Class  = mod_df.Class.map(Class_map)\n",
    "#mod_df.to_csv(path + 'mod_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "38f82023-2ec5-3c00-4d78-a06188170222"
   },
   "outputs": [],
   "source": [
    "#data = df\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(4, 4, figsize=(20,20))\n",
    "sns.despine(left=True)\n",
    "sns.distplot(df['NationalITy'],  kde=False, color=\"b\", ax=axes[0, 0])\n",
    "sns.distplot(df['PlaceofBirth'],        kde=False, color=\"b\", ax=axes[0, 1])\n",
    "sns.distplot(df['StageID'],        kde=False, color=\"b\", ax=axes[0, 2])\n",
    "sns.distplot(df['GradeID'],        kde=False, color=\"b\", ax=axes[0, 3])\n",
    "sns.distplot(df['SectionID'], kde=False, color=\"b\", ax=axes[1, 0])\n",
    "sns.distplot(df['Topic'],  kde=False, color=\"b\", ax=axes[1, 1])\n",
    "sns.distplot(df['Relation'],     kde=False, color=\"b\", ax=axes[1, 2])\n",
    "sns.distplot(df['raisedhands'],  kde=False, color=\"b\", ax=axes[1, 3])\n",
    "sns.distplot(df['VisITedResources'],      kde=False, color=\"b\", ax=axes[2, 0])\n",
    "sns.distplot(df['AnnouncementsView'],      kde=False, color=\"b\", ax=axes[2, 1])\n",
    "sns.distplot(df['Discussion'],    kde=False, color=\"b\", ax=axes[2, 2])\n",
    "sns.distplot(df['ParentAnsweringSurvey'],    kde=False, color=\"b\", ax=axes[2, 3])\n",
    "sns.distplot(df['ParentschoolSatisfaction'],kde=False, color=\"b\", ax=axes[3, 0])\n",
    "sns.distplot(df['StudentAbsenceDays'],       kde=False, color=\"b\", ax=axes[3, 1])\n",
    "sns.distplot(df['Class'],      kde=False, color=\"b\", ax=axes[3, 2])\n",
    "#sns.distplot(df['Fedu'],      kde=False, color=\"b\", ax=axes[3, 3])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "599b1177-0e73-5705-1288-a0a57caf8fb1"
   },
   "outputs": [],
   "source": [
    "categorical_features = (mod_df.select_dtypes(include=['object']).columns.values)\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0b73ad8-4d99-a1fa-21d9-fb966834ef73"
   },
   "outputs": [],
   "source": [
    "mod_df_variable_correlations = mod_df.corr()\n",
    "#variable_correlations\n",
    "heat_map(mod_df_variable_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e65f79a1-9b01-4362-913c-915b29399293"
   },
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "175b03ff-fa4c-91a7-21c4-78f1bdba2cf2"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20e7f508-bcfe-598c-f925-91991f68e5b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "df_copy = pd.get_dummies(mod_df)\n",
    "\n",
    "df1 = df_copy\n",
    "y = np.asarray(df1['ParentschoolSatisfaction'], dtype=\"|S6\")\n",
    "df1 = df1.drop(['ParentschoolSatisfaction'],axis=1)\n",
    "X = df1.values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.50)\n",
    "\n",
    "radm = RandomForestClassifier()\n",
    "radm.fit(Xtrain, ytrain)\n",
    "\n",
    "clf = radm\n",
    "indices = np.argsort(radm.feature_importances_)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print('Feature ranking:')\n",
    "\n",
    "for f in range(df1.shape[1]):\n",
    "    print('%d. feature %d %s (%f)' % (f+1 , \n",
    "                                      indices[f], \n",
    "                                      df1.columns[indices[f]], \n",
    "                                      radm.feature_importances_[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8b34f01-ab3a-73fe-5d2d-5cfb6ac233c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV, SelectKBest\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = [('RandomForestClassifierG', RandomForestClassifier(n_jobs=-1, criterion='gini')),\n",
    "               ('RandomForestClassifierE', RandomForestClassifier(n_jobs=-1, criterion='entropy')),\n",
    "               ('AdaBoostClassifier', AdaBoostClassifier()),\n",
    "               ('ExtraTreesClassifier', ExtraTreesClassifier(n_jobs=-1)),\n",
    "               ('KNeighborsClassifier', KNeighborsClassifier(n_jobs=-1)),\n",
    "               ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "               ('ExtraTreeClassifier', ExtraTreeClassifier()),\n",
    "               ('LogisticRegression', LogisticRegression()),\n",
    "               ('GaussianNB', GaussianNB()),\n",
    "               ('BernoulliNB', BernoulliNB())\n",
    "              ]\n",
    "allscores = []\n",
    "\n",
    "x, Y = mod_df.drop('ParentschoolSatisfaction', axis=1), np.asarray(mod_df['ParentschoolSatisfaction'], dtype=\"|S6\")\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    scores = []\n",
    "    for i in range(20): # 20 runs\n",
    "        roc = cross_val_score(classifier, x, Y)\n",
    "        scores.extend(list(roc))\n",
    "    scores = np.array(scores)\n",
    "    print(name, scores.mean())\n",
    "    new_data = [(name, score) for score in scores]\n",
    "    allscores.extend(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "afa9715f-c227-8290-9152-8b6918127796"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(allscores, columns=['classifier', 'score'])\n",
    "#sns.violinplot('classifier', 'score', data=temp, inner=None, linewidth=0.3)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.factorplot(x='classifier', \n",
    "               y=\"score\",\n",
    "               data=temp, \n",
    "               saturation=1, \n",
    "               kind=\"box\", \n",
    "               ci=None, \n",
    "               aspect=1, \n",
    "               linewidth=1, \n",
    "               size = 10)     \n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8ae55f6-f594-0d16-7d4b-84dd82e14a12"
   },
   "source": [
    "You can note above, that I did the mapping manually. It let me take a peak at the types of data and so on. In the below I am showing how that problem can be cracked without even doing all of those things. Our dataframe has been changed and transformed, so I will load it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5189c2b2-c29f-727d-4746-6ded6acfb1f9"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/xAPI-Edu-Data.csv')\n",
    "df_copy = pd.get_dummies(data)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d307dcd6-c325-57b9-1b7b-20aa90312d77"
   },
   "source": [
    "This magical command: pd.get_dummies adds a lot of columns to the data, and puts 1 and 0 in those various columns. After which the dataframe looks like following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d8b04962-bdb6-cce0-be2e-1f188d4372a6"
   },
   "outputs": [],
   "source": [
    "df_copy.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6d9425f5-a524-a754-061c-1cab70f7499a"
   },
   "outputs": [],
   "source": [
    "df1 = df_copy\n",
    "Y = df1['ParentschoolSatisfaction_Good'].values\n",
    "df1 = df1.drop(['ParentschoolSatisfaction_Good'],axis=1)\n",
    "x = df1.values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(x, Y, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "48f3cc54-d55f-a443-18cd-503a0e5a2d87"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV, SelectKBest\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = [('RandomForestClassifierG', RandomForestClassifier(n_jobs=-1, criterion='gini')),\n",
    "               ('RandomForestClassifierE', RandomForestClassifier(n_jobs=-1, criterion='entropy')),\n",
    "               ('AdaBoostClassifier', AdaBoostClassifier()),\n",
    "               ('ExtraTreesClassifier', ExtraTreesClassifier(n_jobs=-1)),\n",
    "               ('KNeighborsClassifier', KNeighborsClassifier(n_jobs=-1)),\n",
    "               ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "               ('ExtraTreeClassifier', ExtraTreeClassifier()),\n",
    "               ('LogisticRegression', LogisticRegression()),\n",
    "               ('GaussianNB', GaussianNB()),\n",
    "               ('BernoulliNB', BernoulliNB())\n",
    "              ]\n",
    "allscores = []\n",
    "\n",
    "#x, Y = mod_df.drop('ParentschoolSatisfaction', axis=1), np.asarray(mod_df['ParentschoolSatisfaction'], dtype=\"|S6\")\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    scores = []\n",
    "    for i in range(20): # 20 runs\n",
    "        roc = cross_val_score(classifier, x, Y)\n",
    "        scores.extend(list(roc))\n",
    "    scores = np.array(scores)\n",
    "    print(name, scores.mean())\n",
    "    new_data = [(name, score) for score in scores]\n",
    "    allscores.extend(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a6d1812e-4bc1-6c94-a6f4-357db08b69b1"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(allscores, columns=['classifier', 'score'])\n",
    "#sns.violinplot('classifier', 'score', data=temp, inner=None, linewidth=0.3)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.factorplot(x='classifier', \n",
    "               y=\"score\",\n",
    "               data=temp, \n",
    "               saturation=1, \n",
    "               kind=\"box\", \n",
    "               ci=None, \n",
    "               aspect=1, \n",
    "               linewidth=1, \n",
    "               size = 10)     \n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83281dcb-8798-1719-a1cf-cc923c1f69be"
   },
   "source": [
    "Note how our scores are now very high: Thats what onehotencoder or pd.get_dummies does. I still have to figure out how to use onehotencoder. \n",
    "\n",
    "Why? This is very important to note. Now that I explored a little more, here is what I find out: \n",
    "\n",
    "Many learning algorithms either learn a single weight per feature, or they use distances between samples. The former is the case for linear models such as logistic regression, which are easy to explain.\n",
    "\n",
    "Suppose you have a dataset having only a single categorical feature \"nationality\", with values \"UK\", \"French\" and \"US\". Assume, without loss of generality, that these are encoded as 0, 1 and 2. You then have a weight w for this feature in a linear classifier, which will make some kind of decision based on the constraint w×x + b > 0, or equivalently w×x < b.\n",
    "\n",
    "The problem now is that the weight w cannot encode a three-way choice. The three possible values of w×x are 0, w and 2×w. Either these three all lead to the same decision (they're all < b or ≥b) or \"UK\" and \"French\" lead to the same decision, or \"French\" and \"US\" give the same decision. There's no possibility for the model to learn that \"UK\" and \"US\" should be given the same label, with \"French\" the odd one out.\n",
    "\n",
    "By one-hot encoding, you effectively blow up the feature space to three features, which will each get their own weights, so the decision function is now w[UK]x[UK] + w[FR]x[FR] + w[US]x[US] < b, where all the x's are booleans. In this space, such a linear function can express any sum/disjunction of the possibilities (e.g. \"UK or US\", which might be a predictor for someone speaking English).\n",
    "\n",
    "Similarly, any learner based on standard distance metrics (such as k-nearest neighbors) between samples will get confused without one-hot encoding. With the naive encoding and Euclidean distance, the distance between French and US is 1. The distance between US and UK is 2. But with the one-hot encoding, the pairwise distances between [1, 0, 0], [0, 1, 0] and [0, 0, 1] are all equal to √2.\n",
    "\n",
    "This is not true for all learning algorithms; decision trees and derived models such as random forests, if deep enough, can handle categorical variables without one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d141b766-fc64-7a34-7d2c-791c0ed1f70e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
